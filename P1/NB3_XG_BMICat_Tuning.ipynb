{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "O7QDUaq9n1nx",
        "outputId": "23630a39-fc1d-4835-c07e-7811236b5599"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU acceleration enabled\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-10-26 11:22:46,472] A new study created in memory with name: no-name-61f77f9e-16dd-47fc-8a41-b583c8330d35\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory optimized: 2.13 MB → 1.57 MB\n",
            "Memory optimized: 0.68 MB → 0.49 MB\n",
            "Data prepared → 17 features, 7 classes\n",
            "Running Optuna search...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-10-26 11:25:43,532] Trial 0 finished with value: 0.9058137835944052 and parameters: {'learning_rate': 0.010879887248903005, 'max_depth': 9, 'min_child_weight': 10, 'subsample': 0.6610541989055381, 'colsample_bytree': 0.693983470867179, 'gamma': 0.3617694776687417, 'reg_lambda': 0.5620086023734077, 'reg_alpha': 0.7686313645452107}. Best is trial 0 with value: 0.9058137835944052.\n",
            "[I 2025-10-26 11:27:44,080] Trial 1 finished with value: 0.9048478903649219 and parameters: {'learning_rate': 0.017645551606793795, 'max_depth': 6, 'min_child_weight': 3, 'subsample': 0.7803987458625848, 'colsample_bytree': 0.9174113028701733, 'gamma': 0.39598360303052976, 'reg_lambda': 2.771386624380996, 'reg_alpha': 0.8003422132136836}. Best is trial 0 with value: 0.9058137835944052.\n",
            "[I 2025-10-26 11:28:04,319] Trial 2 finished with value: 0.9030453221243351 and parameters: {'learning_rate': 0.19232906307344733, 'max_depth': 6, 'min_child_weight': 3, 'subsample': 0.7188951703647674, 'colsample_bytree': 0.6041598777365972, 'gamma': 0.2968809602597232, 'reg_lambda': 2.117105224872982, 'reg_alpha': 0.4552147633200545}. Best is trial 0 with value: 0.9058137835944052.\n",
            "[I 2025-10-26 11:29:24,436] Trial 3 finished with value: 0.9041397082093049 and parameters: {'learning_rate': 0.028760221292401824, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.7432139791290688, 'colsample_bytree': 0.7947040163496246, 'gamma': 0.4660425420596383, 'reg_lambda': 0.9756142382963582, 'reg_alpha': 0.6528469826205867}. Best is trial 0 with value: 0.9058137835944052.\n",
            "[I 2025-10-26 11:30:35,044] Trial 4 finished with value: 0.9033671552780203 and parameters: {'learning_rate': 0.0285478960339219, 'max_depth': 7, 'min_child_weight': 8, 'subsample': 0.9335077302702837, 'colsample_bytree': 0.8743357018362115, 'gamma': 0.22258312776095968, 'reg_lambda': 2.139390943356906, 'reg_alpha': 0.5535563594408129}. Best is trial 0 with value: 0.9058137835944052.\n",
            "[I 2025-10-26 11:30:35,107] Trial 5 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-10-26 11:30:35,181] Trial 6 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-10-26 11:32:46,217] Trial 7 finished with value: 0.9034958761047018 and parameters: {'learning_rate': 0.01676783878992154, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.8036298888985272, 'colsample_bytree': 0.8302022025584921, 'gamma': 0.3645435614033667, 'reg_lambda': 2.6192501289049783, 'reg_alpha': 0.8259196332583895}. Best is trial 0 with value: 0.9058137835944052.\n",
            "[I 2025-10-26 11:34:58,567] Trial 8 finished with value: 0.9049121782419732 and parameters: {'learning_rate': 0.019540656976003365, 'max_depth': 4, 'min_child_weight': 6, 'subsample': 0.7164165952535385, 'colsample_bytree': 0.9234877173507818, 'gamma': 0.1691543953306187, 'reg_lambda': 2.6803233627530347, 'reg_alpha': 0.23484095164903318}. Best is trial 0 with value: 0.9058137835944052.\n",
            "[I 2025-10-26 11:34:58,632] Trial 9 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-10-26 11:34:58,738] Trial 10 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-10-26 11:37:08,011] Trial 11 finished with value: 0.9035604126776026 and parameters: {'learning_rate': 0.012730753104440658, 'max_depth': 3, 'min_child_weight': 10, 'subsample': 0.6080848072530338, 'colsample_bytree': 0.9804623503602932, 'gamma': 0.2487480370648842, 'reg_lambda': 1.5669601384870604, 'reg_alpha': 0.203804924647036}. Best is trial 0 with value: 0.9058137835944052.\n",
            "[I 2025-10-26 11:39:12,916] Trial 12 finished with value: 0.9025946230713895 and parameters: {'learning_rate': 0.010356764025104964, 'max_depth': 3, 'min_child_weight': 7, 'subsample': 0.671973727887226, 'colsample_bytree': 0.7303046962128528, 'gamma': 0.3270472996624119, 'reg_lambda': 1.66761587416712, 'reg_alpha': 0.2581035846582664}. Best is trial 0 with value: 0.9058137835944052.\n",
            "[I 2025-10-26 11:39:12,990] Trial 13 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-10-26 11:41:16,429] Trial 14 finished with value: 0.904010925208661 and parameters: {'learning_rate': 0.015124239015011745, 'max_depth': 7, 'min_child_weight': 9, 'subsample': 0.8844495284397308, 'colsample_bytree': 0.7240067861987393, 'gamma': 0.16797072071793767, 'reg_lambda': 1.2237582022334859, 'reg_alpha': 0.009382811312092482}. Best is trial 0 with value: 0.9058137835944052.\n",
            "[I 2025-10-26 11:41:16,515] Trial 15 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-10-26 11:41:16,594] Trial 16 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-10-26 11:43:58,100] Trial 17 finished with value: 0.9060066886748677 and parameters: {'learning_rate': 0.010622034228363674, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.6394067422685181, 'colsample_bytree': 0.9319054514530491, 'gamma': 0.29255796004757323, 'reg_lambda': 1.363057594139416, 'reg_alpha': 0.3563477871041465}. Best is trial 17 with value: 0.9060066886748677.\n",
            "[I 2025-10-26 11:47:14,675] Trial 18 finished with value: 0.904526119385199 and parameters: {'learning_rate': 0.010180522842928622, 'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.9740799371885773, 'colsample_bytree': 0.755102802097642, 'gamma': 0.28025795006672005, 'reg_lambda': 1.245852377497006, 'reg_alpha': 0.3976714300515049}. Best is trial 17 with value: 0.9060066886748677.\n",
            "[I 2025-10-26 11:47:14,747] Trial 19 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-10-26 11:47:14,821] Trial 20 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-10-26 11:49:48,570] Trial 21 finished with value: 0.9056204225715524 and parameters: {'learning_rate': 0.01389063983609314, 'max_depth': 4, 'min_child_weight': 6, 'subsample': 0.7042207513329495, 'colsample_bytree': 0.9300015193756124, 'gamma': 0.2879411677973324, 'reg_lambda': 0.785549360542513, 'reg_alpha': 0.1331459831134536}. Best is trial 17 with value: 0.9060066886748677.\n",
            "[I 2025-10-26 11:51:53,796] Trial 22 finished with value: 0.9045259743126202 and parameters: {'learning_rate': 0.013789982695833813, 'max_depth': 3, 'min_child_weight': 9, 'subsample': 0.690842766928682, 'colsample_bytree': 0.8844622907287546, 'gamma': 0.2987698537841197, 'reg_lambda': 0.8829395031210834, 'reg_alpha': 0.10036075396014255}. Best is trial 17 with value: 0.9060066886748677.\n",
            "[I 2025-10-26 11:54:41,074] Trial 23 finished with value: 0.9062644619226965 and parameters: {'learning_rate': 0.010019119283933155, 'max_depth': 5, 'min_child_weight': 4, 'subsample': 0.7375939647312184, 'colsample_bytree': 0.9415393268505807, 'gamma': 0.44264925753709716, 'reg_lambda': 0.7213756256574548, 'reg_alpha': 0.17348666035406535}. Best is trial 23 with value: 0.9062644619226965.\n",
            "[I 2025-10-26 11:57:39,418] Trial 24 finished with value: 0.9044618315081475 and parameters: {'learning_rate': 0.010184230076566023, 'max_depth': 6, 'min_child_weight': 2, 'subsample': 0.7495722534461129, 'colsample_bytree': 0.834159193402158, 'gamma': 0.4393226086227631, 'reg_lambda': 0.6682834419029717, 'reg_alpha': 0.34825165789361756}. Best is trial 23 with value: 0.9062644619226965.\n",
            "[I 2025-10-26 11:57:39,492] Trial 25 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-10-26 11:57:39,575] Trial 26 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-10-26 11:57:39,663] Trial 27 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-10-26 11:57:39,739] Trial 28 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-10-26 11:57:39,819] Trial 29 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-10-26 11:57:39,897] Trial 30 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-10-26 11:57:39,971] Trial 31 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-10-26 11:57:40,049] Trial 32 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-10-26 11:57:40,130] Trial 33 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-10-26 12:00:07,549] Trial 34 finished with value: 0.9046545707913772 and parameters: {'learning_rate': 0.010079021301554535, 'max_depth': 4, 'min_child_weight': 6, 'subsample': 0.6301177353199995, 'colsample_bytree': 0.9471775070469631, 'gamma': 0.21543965852478475, 'reg_lambda': 0.5665888451928633, 'reg_alpha': 0.16759848590923448}. Best is trial 23 with value: 0.9062644619226965.\n",
            "[I 2025-10-26 12:00:07,628] Trial 35 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-10-26 12:00:07,722] Trial 36 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-10-26 12:00:07,823] Trial 37 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-10-26 12:00:07,897] Trial 38 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-10-26 12:00:07,989] Trial 39 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-10-26 12:00:08,152] Trial 40 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-10-26 12:00:08,287] Trial 41 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-10-26 12:02:34,862] Trial 42 finished with value: 0.9048477867416512 and parameters: {'learning_rate': 0.011778697796665202, 'max_depth': 4, 'min_child_weight': 6, 'subsample': 0.7734733762731186, 'colsample_bytree': 0.8961871516100165, 'gamma': 0.23150162930589407, 'reg_lambda': 1.9918278875948574, 'reg_alpha': 0.24200819637511772}. Best is trial 23 with value: 0.9062644619226965.\n",
            "[I 2025-10-26 12:02:35,594] Trial 43 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-10-26 12:02:35,744] Trial 44 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-10-26 12:02:35,956] Trial 45 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-10-26 12:02:36,111] Trial 46 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-10-26 12:05:35,910] Trial 47 finished with value: 0.9043329034349249 and parameters: {'learning_rate': 0.011295949921953761, 'max_depth': 9, 'min_child_weight': 4, 'subsample': 0.8791493228837035, 'colsample_bytree': 0.706785807660542, 'gamma': 0.03851359051118089, 'reg_lambda': 2.3778098802184946, 'reg_alpha': 0.04470266186275047}. Best is trial 23 with value: 0.9062644619226965.\n",
            "[I 2025-10-26 12:05:35,989] Trial 48 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-10-26 12:05:36,062] Trial 49 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-10-26 12:05:36,137] Trial 50 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-10-26 12:05:36,220] Trial 51 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-10-26 12:05:36,306] Trial 52 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-10-26 12:05:36,421] Trial 53 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-10-26 12:08:34,299] Trial 54 finished with value: 0.9067150780770256 and parameters: {'learning_rate': 0.010902439134327814, 'max_depth': 9, 'min_child_weight': 4, 'subsample': 0.7350779317388785, 'colsample_bytree': 0.6393343569320542, 'gamma': 0.4162039232075317, 'reg_lambda': 2.851492169994316, 'reg_alpha': 0.9068870790047262}. Best is trial 54 with value: 0.9067150780770256.\n",
            "[I 2025-10-26 12:11:32,735] Trial 55 finished with value: 0.9063931205754159 and parameters: {'learning_rate': 0.010769988040615998, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.7350150544598527, 'colsample_bytree': 0.6460411268738373, 'gamma': 0.42251320303846074, 'reg_lambda': 2.859469933305055, 'reg_alpha': 0.8655407555700043}. Best is trial 54 with value: 0.9067150780770256.\n",
            "[I 2025-10-26 12:14:28,345] Trial 56 finished with value: 0.9065219035760599 and parameters: {'learning_rate': 0.010872119179856081, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.742277921352372, 'colsample_bytree': 0.633009970327008, 'gamma': 0.4142620273907096, 'reg_lambda': 2.4357028411904436, 'reg_alpha': 0.9284129790688578}. Best is trial 54 with value: 0.9067150780770256.\n",
            "[I 2025-10-26 12:17:12,918] Trial 57 finished with value: 0.9065862743517276 and parameters: {'learning_rate': 0.01093279441726583, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.7476052374357646, 'colsample_bytree': 0.6401447657967232, 'gamma': 0.4995771728784924, 'reg_lambda': 2.8365301289272287, 'reg_alpha': 0.910490911693477}. Best is trial 54 with value: 0.9067150780770256.\n",
            "[I 2025-10-26 12:20:01,622] Trial 58 finished with value: 0.9074876310083104 and parameters: {'learning_rate': 0.011094146426713617, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.7377019359742616, 'colsample_bytree': 0.6464392505901457, 'gamma': 0.4901785320126722, 'reg_lambda': 2.500928677232875, 'reg_alpha': 0.9107966107743035}. Best is trial 58 with value: 0.9074876310083104.\n",
            "[I 2025-10-26 12:22:49,329] Trial 59 finished with value: 0.9071656113327382 and parameters: {'learning_rate': 0.010944991798655601, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.7468948512574107, 'colsample_bytree': 0.6434226057092551, 'gamma': 0.4960680426902727, 'reg_lambda': 2.5545250647726556, 'reg_alpha': 0.9301915294297852}. Best is trial 58 with value: 0.9074876310083104.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Optuna Parameters:\n",
            "{'learning_rate': 0.011094146426713617, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.7377019359742616, 'colsample_bytree': 0.6464392505901457, 'gamma': 0.4901785320126722, 'reg_lambda': 2.500928677232875, 'reg_alpha': 0.9107966107743035}\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import gc\n",
        "import optuna\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from optuna.integration import XGBoostPruningCallback\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "def configure_gpu():\n",
        "    try:\n",
        "        X_demo = np.random.rand(500, 20).astype(np.float32)\n",
        "        y_demo = np.random.randint(0, 2, 500)\n",
        "        dtrain = xgb.DMatrix(X_demo, label=y_demo)\n",
        "        xgb.train(\n",
        "            params={\"objective\": \"binary:logistic\", \"device\": \"cuda\", \"tree_method\": \"hist\"},\n",
        "            dtrain=dtrain,\n",
        "            num_boost_round=1\n",
        "        )\n",
        "        print(\"GPU acceleration enabled\")\n",
        "        return True\n",
        "    except:\n",
        "        print(\"GPU not available, using CPU.\")\n",
        "        return False\n",
        "\n",
        "USE_XGB_GPU = configure_gpu()\n",
        "\n",
        "def reduce_memory_usage(df):\n",
        "    start = df.memory_usage().sum() / 1024**2\n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "        if col_type in [\"int64\", \"int32\"]:\n",
        "            c_min, c_max = df[col].min(), df[col].max()\n",
        "            if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                df[col] = df[col].astype(np.int8)\n",
        "            elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                df[col] = df[col].astype(np.int16)\n",
        "            else:\n",
        "                df[col] = df[col].astype(np.int32)\n",
        "        elif col_type == \"float64\":\n",
        "            df[col] = df[col].astype(np.float32)\n",
        "    end = df.memory_usage().sum() / 1024**2\n",
        "    print(f\"Memory optimized: {start:.2f} MB → {end:.2f} MB\")\n",
        "    return df\n",
        "\n",
        "\n",
        "TRAIN_PATH = \"/content/train.csv\"\n",
        "TEST_PATH = \"/content/test.csv\"\n",
        "TARGET_COL = \"WeightCategory\"\n",
        "ID_COL = \"id\"\n",
        "N_TRIALS = 60\n",
        "N_SPLITS = 5\n",
        "\n",
        "\n",
        "train = pd.read_csv(TRAIN_PATH)\n",
        "test = pd.read_csv(TEST_PATH)\n",
        "train = reduce_memory_usage(train)\n",
        "test = reduce_memory_usage(test)\n",
        "\n",
        "\n",
        "def add_bmi_category(df):\n",
        "    if \"Weight\" in df.columns and \"Height\" in df.columns:\n",
        "        df[\"BMI\"] = df[\"Weight\"] / ((df[\"Height\"] / 100) ** 2)\n",
        "        conditions = [\n",
        "            (df[\"BMI\"] < 18.5),\n",
        "            (df[\"BMI\"] >= 18.5) & (df[\"BMI\"] < 25),\n",
        "            (df[\"BMI\"] >= 25) & (df[\"BMI\"] < 30),\n",
        "            (df[\"BMI\"] >= 30) & (df[\"BMI\"] < 35),\n",
        "            (df[\"BMI\"] >= 35)\n",
        "        ]\n",
        "        categories = [\"Underweight\", \"Normal\", \"Overweight\", \"Obese\", \"Extremely Obese\"]\n",
        "        df[\"BMI_Category\"] = np.select(conditions, categories, default='Unknown') # Set default to a string\n",
        "        df.drop(columns=[\"BMI\"], inplace=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "train = add_bmi_category(train)\n",
        "test = add_bmi_category(test)\n",
        "\n",
        "\n",
        "X = train.drop(columns=[TARGET_COL, ID_COL], errors=\"ignore\")\n",
        "y = train[TARGET_COL]\n",
        "test_features = test.drop(columns=[ID_COL], errors=\"ignore\")\n",
        "\n",
        "\n",
        "for col in set(X.columns) - set(test_features.columns):\n",
        "    test_features[col] = np.nan\n",
        "test_features = test_features[X.columns]\n",
        "\n",
        "cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns\n",
        "for col in cat_cols:\n",
        "    X[col] = X[col].astype(\"category\")\n",
        "    test_features[col] = test_features[col].astype(\"category\")\n",
        "\n",
        "label_enc = LabelEncoder()\n",
        "y_enc = label_enc.fit_transform(y)\n",
        "num_classes = len(label_enc.classes_)\n",
        "print(f\"Data prepared → {X.shape[1]} features, {num_classes} classes\")\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        \"objective\": \"multi:softprob\",\n",
        "        \"num_class\": num_classes,\n",
        "        \"eval_metric\": \"mlogloss\",\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2, log=True),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
        "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
        "        \"gamma\": trial.suggest_float(\"gamma\", 0.0, 0.5),\n",
        "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.5, 3.0),\n",
        "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.0, 1.0),\n",
        "        \"tree_method\": \"hist\",\n",
        "        \"device\": \"cuda\" if USE_XGB_GPU else \"cpu\",\n",
        "        \"seed\": 42,\n",
        "    }\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    accs = []\n",
        "\n",
        "    for tr_idx, va_idx in skf.split(X, y_enc):\n",
        "        X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
        "        y_tr, y_va = y_enc[tr_idx], y_enc[va_idx]\n",
        "        dtrain = xgb.DMatrix(X_tr, label=y_tr, enable_categorical=True)\n",
        "        dvalid = xgb.DMatrix(X_va, label=y_va, enable_categorical=True)\n",
        "\n",
        "        model = xgb.train(\n",
        "            params=params,\n",
        "            dtrain=dtrain,\n",
        "            evals=[(dvalid, \"val\")],\n",
        "            num_boost_round=1500,\n",
        "            early_stopping_rounds=100,\n",
        "            verbose_eval=False,\n",
        "            callbacks=[XGBoostPruningCallback(trial, \"val-mlogloss\")]\n",
        "        )\n",
        "\n",
        "        preds = model.predict(dvalid)\n",
        "        accs.append(accuracy_score(y_va, preds.argmax(axis=1)))\n",
        "\n",
        "        del model, dtrain, dvalid\n",
        "        gc.collect()\n",
        "\n",
        "    return np.mean(accs)\n",
        "\n",
        "\n",
        "print(\"Running Optuna search...\")\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=N_TRIALS)\n",
        "best_params = study.best_params\n",
        "print(\"\\nBest Optuna Parameters:\")\n",
        "print(best_params)"
      ]
    }
  ]
}